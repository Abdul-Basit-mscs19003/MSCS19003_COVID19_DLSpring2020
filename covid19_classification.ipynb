{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_05.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "8OHKMLgFD4w3",
        "7MSMkXEHEBPQ",
        "yIaykAVKEjJt",
        "ZO-fmBjqFKz3",
        "N_B7BRGeFn10",
        "jkr_4TCGF_x3",
        "eqNnqogTGAg7",
        "NILHuddHGBXG",
        "oZ2tllB9EFjm"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0TjZmqWmcC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GxXVsg7wvLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4inBm6jvmKR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "import pandas as pd\n",
        "import seaborn as sn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpOsTnWeyfkB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir './data/'\n",
        "!unzip \"/content/drive/My Drive/DeepAssignment/Assignment05/Assignment 5 Dataset.zip\" -d \"./data/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP-FInga_a2c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = './data/Assignment 5 Dataset/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OR18mGX8vnfg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                       transforms.RandomResizedCrop(224),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.Resize(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                           [0.229, 0.224, 0.225])])\n",
        "\n",
        "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
        "test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n",
        "val_data = datasets.ImageFolder(data_dir + '/validation', transform=test_transforms)\n",
        "\n",
        "\n",
        "trainloader      = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "testloader       = torch.utils.data.DataLoader(test_data, batch_size=8, shuffle=True)\n",
        "validationloader = torch.utils.data.DataLoader(val_data, batch_size=8, shuffle=True)\n",
        "\n",
        "print(\"Classes: \")\n",
        "class_names = train_data.classes\n",
        "print(class_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCJ-XNl0vo48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(inp, title=None):\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)\n",
        "\n",
        "def show_databatch(inputs, classes):\n",
        "    out = torchvision.utils.make_grid(inputs)\n",
        "    imshow(out, title=[class_names[x] for x in classes])\n",
        "\n",
        "inputs, classes = next(iter(trainloader))\n",
        "show_databatch(inputs, classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OHKMLgFD4w3",
        "colab_type": "text"
      },
      "source": [
        "## Task1 (i): VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSHcOtmivqd-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# doing\n",
        "model = models.vgg16(pretrained=True)\n",
        "fc_layers = []\n",
        "fc_layers.extend([nn.Linear(in_features=25088, out_features=130)])\n",
        "fc_layers.extend([nn.ReLU(inplace=True)])\n",
        "fc_layers.extend([nn.Linear(in_features=130, out_features=2)])\n",
        "model.classifier = nn.Sequential(*fc_layers)\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "name = 'vgg16'\n",
        "out_dir = '/content/drive/My Drive/DeepAssignment/Assignment05/models/task1/' + name\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MSMkXEHEBPQ",
        "colab_type": "text"
      },
      "source": [
        "## Task1 (ii): ResNet18"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPrA8bx9EFgo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "fc_layers = []\n",
        "fc_layers.extend([nn.Linear(in_features=512, out_features=130)])\n",
        "fc_layers.extend([nn.ReLU(inplace=True)])\n",
        "fc_layers.extend([nn.Linear(in_features=130, out_features=2)])\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "model.fc = nn.Sequential(*fc_layers)\n",
        "name = 'resnet18'\n",
        "out_dir = '/content/drive/My Drive/DeepAssignment/Assignment05/models/task1/' + name\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIaykAVKEjJt",
        "colab_type": "text"
      },
      "source": [
        "## Task2 (i)- a VGG16 (Conv1, Conv2, Conv3 are frozen)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRITue__Eicj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.vgg16(pretrained=True)\n",
        "fc_layers = []\n",
        "fc_layers.extend([nn.Linear(in_features=25088, out_features=130)])\n",
        "fc_layers.extend([nn.ReLU(inplace=True)])\n",
        "fc_layers.extend([nn.Linear(in_features=130, out_features=2)])\n",
        "models.classifier = nn.Sequential(*fc_layers)\n",
        "for i,param in enumerate(model.features[:17].parameters()): # freezing 7 conv layers, and remaining 6 are unfrozen\n",
        "    param.requires_grad = False\n",
        "name = 'vgg16'\n",
        "out_dir = '/content/drive/My Drive/DeepAssignment/Assignment05/models/task2a/' + name\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO-fmBjqFKz3",
        "colab_type": "text"
      },
      "source": [
        "## Task2 (i)- b VGG16 (Conv1, Conv2 are frozen)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe7Uq6WlFPdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.vgg16(pretrained=True)\n",
        "fc_layers = []\n",
        "fc_layers.extend([nn.Linear(in_features=25088, out_features=130)])\n",
        "fc_layers.extend([nn.ReLU(inplace=True)])\n",
        "fc_layers.extend([nn.Linear(in_features=130, out_features=2)])\n",
        "models.classifier = nn.Sequential(*fc_layers)\n",
        "for param in model.features[:10].parameters(): # freezing 4 conv layers, and remaining 9 are unfrozen\n",
        "    param.requires_grad = False\n",
        "name = 'vgg16'\n",
        "out_dir = '/content/drive/My Drive/DeepAssignment/Assignment05/models/task2b/' + name\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_B7BRGeFn10",
        "colab_type": "text"
      },
      "source": [
        "## Task2 (i)- c VGG16 (nothing is frozen)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lffqGCPaFsRR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.vgg16(pretrained=True)\n",
        "fc_layers = []\n",
        "fc_layers.extend([nn.Linear(in_features=25088, out_features=130)])\n",
        "fc_layers.extend([nn.ReLU(inplace=True)])\n",
        "fc_layers.extend([nn.Linear(in_features=130, out_features=2)])\n",
        "model.classifier = nn.Sequential(*fc_layers)\n",
        "name = 'vgg16'\n",
        "out_dir = '/content/drive/My Drive/DeepAssignment/Assignment05/models/task2c/' + name\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkr_4TCGF_x3",
        "colab_type": "text"
      },
      "source": [
        "## Task2 (ii)- a resnet18 (Layer1, Layer2, Layer3 are frozen)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC14i1_uGAIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "fc_layers = []\n",
        "fc_layers.extend([nn.Linear(in_features=512, out_features=130)])\n",
        "fc_layers.extend([nn.ReLU(inplace=True)])\n",
        "fc_layers.extend([nn.Linear(in_features=130, out_features=2)])\n",
        "model.fc = nn.Sequential(*fc_layers)\n",
        "for i, child in enumerate(model.children()):\n",
        "    if i < 7:\n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = False\n",
        "name = 'resnet18'\n",
        "out_dir = '/content/drive/My Drive/DeepAssignment/Assignment05/models/task2a/' + name\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqNnqogTGAg7",
        "colab_type": "text"
      },
      "source": [
        "## Task2 (ii)- b resnet18 (layer1 is frozen)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvIY8qprGBFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "fc_layers = []\n",
        "fc_layers.extend([nn.Linear(in_features=512, out_features=130)])\n",
        "fc_layers.extend([nn.ReLU(inplace=True)])\n",
        "fc_layers.extend([nn.Linear(in_features=130, out_features=2)])\n",
        "model.fc = nn.Sequential(*fc_layers)\n",
        "for i, child in enumerate(model.children()):\n",
        "    if i < 5:\n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = False\n",
        "name = 'resnet18'\n",
        "out_dir = '/content/drive/My Drive/DeepAssignment/Assignment05/models/task2b/' + name\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NILHuddHGBXG",
        "colab_type": "text"
      },
      "source": [
        "## Task2 (ii)- c (nothing is frozen)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_XQR91tGBjl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "fc_layers = []\n",
        "fc_layers.extend([nn.Linear(in_features=512, out_features=130)])\n",
        "fc_layers.extend([nn.ReLU(inplace=True)])\n",
        "fc_layers.extend([nn.Linear(in_features=130, out_features=2)])\n",
        "model.fc = nn.Sequential(*fc_layers)\n",
        "name = 'resnet18'\n",
        "out_dir = '/content/drive/My Drive/DeepAssignment/Assignment05/models/task2c/' + name\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZ2tllB9EFjm",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJrJqEJ8vvB8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Epochs = 25\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ohst6LaDEw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_acc_and_loss(model, criterion, loader):\n",
        "    model.eval()\n",
        "    loss_sum = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss_sum = loss_sum + loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return correct*100/total, loss_sum/len(loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVLPwNQqO_d6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "#if you have gpu then you need to convert the network and data to cuda\n",
        "#the easiest way is to first check for device and then convert network and data to device\n",
        "\n",
        "\n",
        "\n",
        "train_loss = np.zeros(Epochs)\n",
        "valid_loss = np.zeros(Epochs)\n",
        "\n",
        "train_acc = np.zeros(Epochs)\n",
        "valid_acc = np.zeros(Epochs)\n",
        "\n",
        "for epoch in range(Epochs):  # loop over the dataset multiple times\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    pbar = tqdm(enumerate(trainloader))\n",
        "    for i, data in pbar:\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # In PyTorch, we need to set the gradients to zero before starting to do backpropragation \n",
        "        # because PyTorch accumulates the gradients on subsequent backward passes. \n",
        "        # This is convenient while training RNNs. \n",
        "        # So, the default action is to accumulate the gradients on every loss.backward() call\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)               #----> forward pass\n",
        "        loss = criterion(outputs, labels)   #----> compute loss\n",
        "        loss.backward()                     #----> backward pass\n",
        "        optimizer.step()                    #----> weights update\n",
        "\n",
        "        # print statistics\n",
        "        \n",
        "        \n",
        "        pbar.set_description(\n",
        "            'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, i * len(inputs), len(trainloader.dataset),\n",
        "                100. * i / len(trainloader),\n",
        "                loss.item()))\n",
        "    pbar.set_description(' ')\n",
        "    train_acc[epoch], train_loss[epoch] = compute_acc_and_loss(model, criterion, trainloader)\n",
        "    valid_acc[epoch], valid_loss[epoch] = compute_acc_and_loss(model, criterion, validationloader)\n",
        "    print('Train Epoch: {}  Train Accuracy: {:.2f} Train Loss : {:.6f} \\\n",
        "                            Validation Accuracy: {:.2f}  Validation Loss : {:.6f} '.format( epoch, \n",
        "                            train_acc[epoch], train_loss[epoch], \n",
        "                            valid_acc[epoch], valid_loss[epoch]))\n",
        "    torch.save(model.state_dict(), out_dir + '/ft_' + str(epoch) +  '.pth')\n",
        "\n",
        "print('Finished Training')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceBy-HuHzf0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = '/content/drive/My Drive/DeepAssignment/Assignment05/models/'\n",
        "np.save(output + 'task1_vgg16.npy', [train_loss, valid_loss, train_acc, valid_acc])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oG61oNeoEJd_",
        "colab_type": "text"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GONXeSvKVTv5"
      },
      "source": [
        "## Task1 (i): VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2uR-nhFvVTwL",
        "colab": {}
      },
      "source": [
        "model = models.vgg16(pretrained=True)\n",
        "fc_layers = []\n",
        "fc_layers.extend([nn.Linear(in_features=25088, out_features=130)])\n",
        "fc_layers.extend([nn.ReLU(inplace=True)])\n",
        "fc_layers.extend([nn.Linear(in_features=130, out_features=2)])\n",
        "model.classifier = nn.Sequential(*fc_layers)\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "name = 'vgg16'\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print('model created')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1GPcTX_VgJF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = '/content/drive/My Drive/DeepAssignment/Assignment05/models/'\n",
        "train_loss, valid_loss, train_acc, valid_acc  = np.load(output + 'task1_' + name + '.npy')\n",
        "best_model = np.argmax(valid_acc)\n",
        "r = best_model+1\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.arange(r), train_loss[:r], 'r', np.arange(r), valid_loss[:r], 'b')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim(0.15, 0.55)\n",
        "plt.legend(['Training Loss', 'Validation Loss'])\n",
        "plt.show()\n",
        "plt.figure()\n",
        "plt.plot(np.arange(r), train_acc[:r], 'r', np.arange(r), valid_acc[:r], 'b')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim(70, 100)\n",
        "plt.legend(['Training Acc', 'Validation Acc'])\n",
        "plt.show()\n",
        "\n",
        "print(best_model, valid_acc[best_model])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7imCp07WPrO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights_path = '/content/drive/My Drive/DeepAssignment/Assignment05/models1' + '/vgg16_FC_Only' + '.pth'\n",
        "model.load_state_dict(torch.load(weights_path))\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print('loaded')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MIwQEEFWVJD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Training Dataset: ')\n",
        "print_statistics(model, trainloader)\n",
        "print('Validation Dataset: ')\n",
        "print_statistics(model, validationloader)\n",
        "print('Test Dataset: ')\n",
        "print_statistics(model, testloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gLBZOPBqVTwr"
      },
      "source": [
        "## Task1 (ii): ResNet18"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qwi6PJykVTwu",
        "colab": {}
      },
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "fc_layers = []\n",
        "fc_layers.extend([nn.Linear(in_features=512, out_features=130)])\n",
        "fc_layers.extend([nn.ReLU(inplace=True)])\n",
        "fc_layers.extend([nn.Linear(in_features=130, out_features=2)])\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "model.fc = nn.Sequential(*fc_layers)\n",
        "name = 'resnet18'\n",
        "out_dir = '/content/drive/My Drive/DeepAssignment/Assignment05/models/task1/' + name\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print('model created')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8F8TaNMVjL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = '/content/drive/My Drive/DeepAssignment/Assignment05/models/'\n",
        "train_loss, valid_loss, train_acc, valid_acc  = np.load(output + 'task1_' + name + '.npy')\n",
        "best_model = np.argmax(valid_acc)\n",
        "r = best_model+1\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.arange(r), train_loss[:r], 'r', np.arange(r), valid_loss[:r], 'b')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim(0.15, 0.55)\n",
        "plt.legend(['Training Loss', 'Validation Loss'])\n",
        "plt.show()\n",
        "plt.figure()\n",
        "plt.plot(np.arange(r), train_acc[:r], 'r', np.arange(r), valid_acc[:r], 'b')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim(70, 100)\n",
        "plt.legend(['Training Acc', 'Validation Acc'])\n",
        "plt.show()\n",
        "\n",
        "print(best_model, valid_acc[best_model])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6w7v4zFCWNAu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights_path = '/content/drive/My Drive/DeepAssignment/Assignment05/models1' + '/res18_FC_Only' + '.pth'\n",
        "model.load_state_dict(torch.load(weights_path))\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print('loaded')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PeQ1g_VWWrJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Training Dataset: ')\n",
        "print_statistics(model, trainloader)\n",
        "print('Validation Dataset: ')\n",
        "print_statistics(model, validationloader)\n",
        "print('Test Dataset: ')\n",
        "print_statistics(model, testloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Yh-LI17JVTw4"
      },
      "source": [
        "## Task2 (i)- a VGG16 (Conv1, Conv2, Conv3 are frozen)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3af1SLlJVTw6",
        "colab": {}
      },
      "source": [
        "model = models.vgg16(pretrained=True)\n",
        "fc_layers = []\n",
        "fc_layers.extend([nn.Linear(in_features=25088, out_features=130)])\n",
        "fc_layers.extend([nn.ReLU(inplace=True)])\n",
        "fc_layers.extend([nn.Linear(in_features=130, out_features=2)])\n",
        "model.classifier = nn.Sequential(*fc_layers)\n",
        "for i,param in enumerate(model.features[:17].parameters()): # freezing 7 conv layers, and remaining 6 are unfrozen\n",
        "    param.requires_grad = False\n",
        "name = 'vgg16'\n",
        "out_dir = '/content/drive/My Drive/DeepAssignment/Assignment05/models/task2a/' + name\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print('model created')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CAp_-0zVnc5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = '/content/drive/My Drive/DeepAssignment/Assignment05/models/'\n",
        "train_loss, valid_loss, train_acc, valid_acc  = np.load(output + 'task2a_' + name + '.npy')\n",
        "best_model = np.argmax(valid_acc)\n",
        "r = best_model+1\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.arange(r), train_loss[:r], 'r', np.arange(r), valid_loss[:r], 'b')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim(0.15, 0.55)\n",
        "plt.legend(['Training Loss', 'Validation Loss'])\n",
        "plt.show()\n",
        "plt.figure()\n",
        "plt.plot(np.arange(r), train_acc[:r], 'r', np.arange(r), valid_acc[:r], 'b')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim(70, 100)\n",
        "plt.legend(['Training Acc', 'Validation Acc'])\n",
        "plt.show()\n",
        "\n",
        "print(best_model, valid_acc[best_model])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7-DV231WLle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights_path = '/content/drive/My Drive/DeepAssignment/Assignment05/models1' + '/vgg16_c45' + '.pth'\n",
        "model.load_state_dict(torch.load(weights_path))\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print('loaded')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj3OqRV4WXzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Training Dataset: ')\n",
        "print_statistics(model, trainloader)\n",
        "print('Validation Dataset: ')\n",
        "print_statistics(model, validationloader)\n",
        "print('Test Dataset: ')\n",
        "print_statistics(model, testloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HlhQ2nepVTxB"
      },
      "source": [
        "## Task2 (i)- b VGG16 (Conv1, Conv2 are frozen)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zr3FzyLQVTxC",
        "colab": {}
      },
      "source": [
        "model = models.vgg16(pretrained=True)\n",
        "fc_layers = []\n",
        "fc_layers.extend([nn.Linear(in_features=25088, out_features=130)])\n",
        "fc_layers.extend([nn.ReLU(inplace=True)])\n",
        "fc_layers.extend([nn.Linear(in_features=130, out_features=2)])\n",
        "model.classifier = nn.Sequential(*fc_layers)\n",
        "for param in model.features[:10].parameters(): # freezing 4 conv layers, and remaining 9 are unfrozen\n",
        "    param.requires_grad = False\n",
        "name = 'vgg16'\n",
        "out_dir = '/content/drive/My Drive/DeepAssignment/Assignment05/models/task2b/' + name\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print('model created')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UMN7dUIVrM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = '/content/drive/My Drive/DeepAssignment/Assignment05/models/'\n",
        "train_loss, valid_loss, train_acc, valid_acc  = np.load(output + 'task2b_' + name + '.npy')\n",
        "best_model = np.argmax(valid_acc)\n",
        "r = best_model+1\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.arange(r), train_loss[:r], 'r', np.arange(r), valid_loss[:r], 'b')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim(0.15, 0.55)\n",
        "plt.legend(['Training Loss', 'Validation Loss'])\n",
        "plt.show()\n",
        "plt.figure()\n",
        "plt.plot(np.arange(r), train_acc[:r], 'r', np.arange(r), valid_acc[:r], 'b')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim(70, 100)\n",
        "plt.legend(['Training Acc', 'Validation Acc'])\n",
        "plt.show()\n",
        "\n",
        "print(best_model, valid_acc[best_model])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vb0ObmggWK4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights_path = '/content/drive/My Drive/DeepAssignment/Assignment05/models1' + '/vgg16_c345' + '.pth'\n",
        "model.load_state_dict(torch.load(weights_path))\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print('loaded')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOncXyRKWY-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Training Dataset: ')\n",
        "print_statistics(model, trainloader)\n",
        "print('Validation Dataset: ')\n",
        "print_statistics(model, validationloader)\n",
        "print('Test Dataset: ')\n",
        "print_statistics(model, testloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SYQwSdqDVTxL"
      },
      "source": [
        "## Task2 (i)- c VGG16 (nothing is frozen)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_Wm8lXtmVTxM",
        "colab": {}
      },
      "source": [
        "model = models.vgg16(pretrained=True)\n",
        "fc_layers = []\n",
        "fc_layers.extend([nn.Linear(in_features=25088, out_features=130)])\n",
        "fc_layers.extend([nn.ReLU(inplace=True)])\n",
        "fc_layers.extend([nn.Linear(in_features=130, out_features=2)])\n",
        "model.classifier = nn.Sequential(*fc_layers)\n",
        "name = 'vgg16'\n",
        "out_dir = '/content/drive/My Drive/DeepAssignment/Assignment05/models/task2c/' + name\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print('model created')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBi5mQCnVzNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = '/content/drive/My Drive/DeepAssignment/Assignment05/models/'\n",
        "train_loss, valid_loss, train_acc, valid_acc  = np.load(output + 'task2c_' + name + '.npy')\n",
        "best_model = np.argmax(valid_acc)\n",
        "r = best_model+1\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.arange(r), train_loss[:r], 'r', np.arange(r), valid_loss[:r], 'b')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim(0.15, 0.55)\n",
        "plt.legend(['Training Loss', 'Validation Loss'])\n",
        "plt.show()\n",
        "plt.figure()\n",
        "plt.plot(np.arange(r), train_acc[:r], 'r', np.arange(r), valid_acc[:r], 'b')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim(70, 100)\n",
        "plt.legend(['Training Acc', 'Validation Acc'])\n",
        "plt.show()\n",
        "\n",
        "print(best_model, valid_acc[best_model])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxDusnpNWJUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights_path = '/content/drive/My Drive/DeepAssignment/Assignment05/models1' + '/vgg16_entire' + '.pth'\n",
        "model.load_state_dict(torch.load(weights_path))\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print('loaded')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSs4MgfbWall",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Training Dataset: ')\n",
        "print_statistics(model, trainloader)\n",
        "print('Validation Dataset: ')\n",
        "print_statistics(model, validationloader)\n",
        "print('Test Dataset: ')\n",
        "print_statistics(model, testloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AAXel03qVTxU"
      },
      "source": [
        "## Task2 (ii)- a resnet18 (Layer1, Layer2, Layer3 are frozen)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_Ja3mBMUVTxW",
        "colab": {}
      },
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "fc_layers = []\n",
        "fc_layers.extend([nn.Linear(in_features=512, out_features=130)])\n",
        "fc_layers.extend([nn.ReLU(inplace=True)])\n",
        "fc_layers.extend([nn.Linear(in_features=130, out_features=2)])\n",
        "model.fc = nn.Sequential(*fc_layers)\n",
        "for i, child in enumerate(model.children()):\n",
        "    if i < 7:\n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = False\n",
        "name = 'resnet18'\n",
        "out_dir = '/content/drive/My Drive/DeepAssignment/Assignment05/models/task2a/' + name\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print('model created')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MDzIZcOV3yk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = '/content/drive/My Drive/DeepAssignment/Assignment05/models/'\n",
        "train_loss, valid_loss, train_acc, valid_acc  = np.load(output + 'task2a_' + name + '.npy')\n",
        "best_model = np.argmax(valid_acc)\n",
        "r = best_model+1\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.arange(r), train_loss[:r], 'r', np.arange(r), valid_loss[:r], 'b')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim(0.15, 0.55)\n",
        "plt.legend(['Training Loss', 'Validation Loss'])\n",
        "plt.show()\n",
        "plt.figure()\n",
        "plt.plot(np.arange(r), train_acc[:r], 'r', np.arange(r), valid_acc[:r], 'b')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim(70, 100)\n",
        "plt.legend(['Training Acc', 'Validation Acc'])\n",
        "plt.show()\n",
        "\n",
        "print(best_model, valid_acc[best_model])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrceEAAeWIYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights_path = '/content/drive/My Drive/DeepAssignment/Assignment05/models1' + '/res18_L4' + '.pth'\n",
        "model.load_state_dict(torch.load(weights_path))\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print('loaded')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s70f1F3UWcBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Training Dataset: ')\n",
        "print_statistics(model, trainloader)\n",
        "print('Validation Dataset: ')\n",
        "print_statistics(model, validationloader)\n",
        "print('Test Dataset: ')\n",
        "print_statistics(model, testloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gfZqvwkLVTxc"
      },
      "source": [
        "## Task2 (ii)- b resnet18 (layer1 is frozen)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uVGxiWQZVTxf",
        "colab": {}
      },
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "fc_layers = []\n",
        "fc_layers.extend([nn.Linear(in_features=512, out_features=130)])\n",
        "fc_layers.extend([nn.ReLU(inplace=True)])\n",
        "fc_layers.extend([nn.Linear(in_features=130, out_features=2)])\n",
        "model.fc = nn.Sequential(*fc_layers)\n",
        "for i, child in enumerate(model.children()):\n",
        "    if i < 5:\n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = False\n",
        "name = 'resnet18'\n",
        "out_dir = '/content/drive/My Drive/DeepAssignment/Assignment05/models/task2b/' + name\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print('model created')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZDDGO_0V5Vt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = '/content/drive/My Drive/DeepAssignment/Assignment05/models/'\n",
        "train_loss, valid_loss, train_acc, valid_acc  = np.load(output + 'task2b_' + name + '.npy')\n",
        "best_model = np.argmax(valid_acc)\n",
        "r = best_model+1\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.arange(r), train_loss[:r], 'r', np.arange(r), valid_loss[:r], 'b')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim(0.15, 0.55)\n",
        "plt.legend(['Training Loss', 'Validation Loss'])\n",
        "plt.show()\n",
        "plt.figure()\n",
        "plt.plot(np.arange(r), train_acc[:r], 'r', np.arange(r), valid_acc[:r], 'b')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim(70, 100)\n",
        "plt.legend(['Training Acc', 'Validation Acc'])\n",
        "plt.show()\n",
        "\n",
        "print(best_model, valid_acc[best_model])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyykULiNWHeo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights_path = '/content/drive/My Drive/DeepAssignment/Assignment05/models1' + '/res18_L234' + '.pth'\n",
        "model.load_state_dict(torch.load(weights_path))\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print('loaded')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xWAb6kmWdKS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Training Dataset: ')\n",
        "print_statistics(model, trainloader)\n",
        "print('Validation Dataset: ')\n",
        "print_statistics(model, validationloader)\n",
        "print('Test Dataset: ')\n",
        "print_statistics(model, testloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "66_R76oSVTxl"
      },
      "source": [
        "## Task2 (ii)- c (nothing is frozen)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lp0SNf9MVTxl",
        "colab": {}
      },
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "fc_layers = []\n",
        "fc_layers.extend([nn.Linear(in_features=512, out_features=130)])\n",
        "fc_layers.extend([nn.ReLU(inplace=True)])\n",
        "fc_layers.extend([nn.Linear(in_features=130, out_features=2)])\n",
        "model.fc = nn.Sequential(*fc_layers)\n",
        "name = 'resnet18'\n",
        "out_dir = '/content/drive/My Drive/DeepAssignment/Assignment05/models/task2c/' + name\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print('model created')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZMor_l3PEMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = '/content/drive/My Drive/DeepAssignment/Assignment05/models/'\n",
        "train_loss, valid_loss, train_acc, valid_acc  = np.load(output + 'task2c_' + name + '.npy')\n",
        "best_model = np.argmax(valid_acc)\n",
        "r = best_model+1\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.arange(r), train_loss[:r], 'r', np.arange(r), valid_loss[:r], 'b')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim(0.15, 0.55)\n",
        "plt.legend(['Training Loss', 'Validation Loss'])\n",
        "plt.show()\n",
        "plt.figure()\n",
        "plt.plot(np.arange(r), train_acc[:r], 'r', np.arange(r), valid_acc[:r], 'b')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim(70, 100)\n",
        "plt.legend(['Training Acc', 'Validation Acc'])\n",
        "plt.show()\n",
        "\n",
        "print(best_model, valid_acc[best_model])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKa6vQ8ZPG9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights_path = '/content/drive/My Drive/DeepAssignment/Assignment05/models1' + '/res18_entire' + '.pth'\n",
        "model.load_state_dict(torch.load(weights_path))\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print('loaded')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiJzWz4kWfbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Training Dataset: ')\n",
        "print_statistics(model, trainloader)\n",
        "print('Validation Dataset: ')\n",
        "print_statistics(model, validationloader)\n",
        "print('Test Dataset: ')\n",
        "print_statistics(model, testloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGiRI-cvWgYa",
        "colab_type": "text"
      },
      "source": [
        "## Helper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUhwxYm0REfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_statistics(model, loader):\n",
        "    model.eval()\n",
        "    actual_labels = []\n",
        "    predic_labels = []\n",
        "\n",
        "    cm = np.zeros((2,2))\n",
        "\n",
        "    class_correct = list(0. for i in range(2))\n",
        "    class_total = list(0. for i in range(2))\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "        \n",
        "            actual_labels.extend(labels)\n",
        "            predic_labels.extend(predicted)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            c = (predicted == labels).squeeze()\n",
        "            for i in np.arange(len(labels)):\n",
        "                cm[labels[i], predicted[i]] = cm[labels[i], predicted[i]] + 1\n",
        "                label = labels[i]\n",
        "                class_correct[label] += c[i].item()\n",
        "                class_total[label] += 1\n",
        "\n",
        "\n",
        "    for i in range(2):\n",
        "        print('  Accuracy of %5s : %.2f %%' % (class_names[i], 100 * class_correct[i] / class_total[i]))\n",
        "    print('  Accuracy on whole test set : %.2f %%' %(100*correct/total) )\n",
        "    print('  F1-Score on whole test set : %.2f %%' %(f1_score(torch.FloatTensor(actual_labels), torch.FloatTensor(predic_labels))))\n",
        "\n",
        "    df_cm = pd.DataFrame(cm.astype(int), columns=class_names, index = class_names)\n",
        "    df_cm.index.name = 'Actual'\n",
        "    df_cm.columns.name = 'Predicted'\n",
        "    plt.figure(figsize = (4,4))\n",
        "    sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 10}, fmt=\"d\")\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59j54eIpg9qo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}